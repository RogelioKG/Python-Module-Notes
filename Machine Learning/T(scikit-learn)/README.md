# scikit-learn

[![RogelioKG/scikit-learn](https://img.shields.io/badge/Sync%20with%20HackMD-grey?logo=markdown)](https://hackmd.io/@RogelioKG/scikit-learn)

## References
+ ğŸ”— [**Documentation - scikit-learn**](https://scikit-learn.org/)

## Cheatsheet

![ML map](https://scikit-learn.org/1.4/_static/ml_map.png)

## Note
|ğŸš¨ <span class="caution">CAUTION</span>|
|:---|
| scikit-learn ä¸­ä½¿ç”¨çš„ <mark>neural network</mark> ä»¥ <mark>CPU</mark> ä½œç‚ºè¨ˆç®—å¹³å° |

## Persistence
> ä½¿ç”¨ `joblib`
```py
import joblib

# ...

# è¨“ç·´æ¨¡å‹
model.fit(X_train, y_train)

# æ¨¡å‹æŒä¹…åŒ–
joblib.dump(model, 'iris.joblib')

# è¼‰å…¥æ¨¡å‹
model = joblib.load('iris.joblib')
```

## Classification
```py
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# 1. æº–å‚™è³‡æ–™
data = load_iris()
X, y = data.data, data.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 2. å»ºç«‹æ¨¡å‹
model = RandomForestClassifier(n_estimators=100, random_state=42)

# 3. è¨“ç·´æ¨¡å‹
model.fit(X_train, y_train)

# 4. é æ¸¬èˆ‡è©•ä¼°
predictions = model.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, predictions):.2f}")
```
```py
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# 1. ç”¢ç”Ÿè³‡æ–™
X, y = make_classification(n_samples=100, random_state=1)
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)

# 2. å»ºç«‹æ¨¡å‹
clf = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, random_state=1)

# 3. è¨“ç·´æ¨¡å‹
clf.fit(X_train, y_train)

# 4. é€²è¡Œé æ¸¬
print(f"Accuracy: {clf.score(X_test, y_test):.2f}")
```


## Regression
```py
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# 1. æº–å‚™è³‡æ–™
X, y = make_regression(n_samples=200, n_features=1, noise=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 2. å»ºç«‹æ¨¡å‹
model = LinearRegression()

# 3. è¨“ç·´æ¨¡å‹
model.fit(X_train, y_train)

# 4. é æ¸¬èˆ‡è©•ä¼°
predictions = model.predict(X_test)
mse = mean_squared_error(y_test, predictions)
print(f"MSE: {mse:.2f}")
print(f"Coefficient: {model.coef_[0]:.2f}")
```


## Clustering

```py
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans

# 1. æº–å‚™è³‡æ–™
X, true_labels = make_blobs(n_samples=300, centers=3, cluster_std=0.60, random_state=0)

# 2. å»ºç«‹æ¨¡å‹
model = KMeans(n_clusters=3, n_init='auto', random_state=0)

# 3. è¨“ç·´æ¨¡å‹ (ä¸éœ€è¦ true_labels)
model.fit(X)

# 4. å–å¾—çµæœ
predict_labels = model.predict(X)
print(f"Labels: {predict_labels}")
print(f"Cluster Centers: {model.cluster_centers_}")
```

## Dim Reduction

```py
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA

# 1. æº–å‚™è³‡æ–™
data = load_iris()
X = data.data
print(f"Shape: {X.shape}") # (150, 4)

# 2. å»ºç«‹æ¨¡å‹ (ç›®æ¨™é™åˆ° 2 ç¶­)
pca = PCA(n_components=2)

# 3. è¨“ç·´ä¸¦è½‰æ› (Fit & Transform)
X_reduced = pca.fit_transform(X)

# 4. æŸ¥çœ‹çµæœ
print(f"Reduced Shape: {X_reduced.shape}") # (150, 2)
print(f"Explained Variance Ratio: {pca.explained_variance_ratio_}")
```

## Metrics
```py
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 1. æº–ç¢ºç‡
print(accuracy_score(y_true, y_pred))

# 2. åˆ†é¡å ±å‘Š
# Precision: æ­£ç¢ºé æ¸¬æ˜¯è²“ / é æ¸¬æ˜¯è²“
# Recall: æ­£ç¢ºé æ¸¬æ˜¯è²“ / å¯¦éš›å¤šå°‘è²“
print(classification_report(y_true, y_pred))

# 3. æ··æ·†çŸ©é™£
print(confusion_matrix(y_true, y_pred))
```

```py
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

y_true = [3.0, -0.5, 2.0, 7.0]
y_pred = [2.5,  0.0, 2.1, 7.8]

# 1. MSE
print(f"MSE: {mean_squared_error(y_true, y_pred):.2f}") 

# 2. MAE
print(f"MAE: {mean_absolute_error(y_true, y_pred):.2f}")

# 3. R2 Score
print(f"R2 Score: {r2_score(y_true, y_pred):.2f}")
```
