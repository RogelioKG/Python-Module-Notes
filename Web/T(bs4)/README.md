# bs4

## References
+ ğŸ”— [**oxxostudio - beautifulsoup**](https://steam.oxxostudio.tw/category/python/spider/beautiful-soup.html)

## Tips
+ ä¸Šç¶²çˆ¬
  ```py
  url = "https://water.taiwanstat.com/"
  response = requests.get(url)
  soup = BeautifulSoup(response.text, "html.parser")
  ```
+ æœ¬åœ°çˆ¬
  ```py
  url = "./practice.html"
  with open(url, mode="r", encoding="utf-8") as htmlFile:
      html_content = htmlFile.read()
  soup = BeautifulSoup(html_content, "html.parser")
  ```

## Class

### `PageElement`
> ...

### `Tag`
> ç¹¼æ‰¿è‡ª PageElementï¼Œä»£è¡¨ä¸€å€‹ HTML å…ƒç´ 

### `BeautifulSoup`
> ç¹¼æ‰¿è‡ª Tag

+ å±¬æ€§
  ```py
  soup.name      # éæ¿¾å™¨ - tag åç¨± (æ¿¾å‡º Tag çš„éæ¿¾å™¨æœƒè¢«è¨˜éŒ„åœ¨å®ƒçš„å±¬æ€§å…§)
  soup.attrs     # éæ¿¾å™¨ - å±¬æ€§å­—å…¸
  soup.contents  # å…§å®¹ (list)
  soup.text      # å…§å®¹ (str) (é€šå¸¸å°±æ˜¯ä½ è¦çˆ¬çš„å…§å®¹)
  soup["href"]   # æˆ–è€…ä½ æƒ³è¦å±¬æ€§è£¡çš„æŸå€‹å…§å®¹
  ```
+ æ–¹æ³•
  ```py
  soup: BeautifulSoup             # ç„¡è«–æ˜¯ BeautifulSoup é‚„æ˜¯ Tag
  tags: Tag                       # éƒ½å¯ä»¥ä½¿ç”¨ä¸‹åˆ—çš„æ–¹æ³• (ç•¢ç«Ÿä»–å€‘æ˜¯ç¹¼æ‰¿é—œä¿‚)

  soup.prettify()                 # æ¼‚äº®æ ¼å¼

  soup.select()                   # ä»¥ CSS é¸æ“‡å™¨çš„æ–¹å¼å°‹æ‰¾æŒ‡å®šçš„ tag
                                  # -> ResultSet[Tag]

                                  # name:      éæ¿¾å™¨ - tag åç¨± (ä¾‹å¦‚ "div")
                                  # attrs:     éæ¿¾å™¨ - å±¬æ€§å­—å…¸ (ä¾‹å¦‚ {"class": "contents_box02"})
                                  # recursive: é è¨­ Trueï¼Œæœƒæœå°‹å…§å®¹ã€æ‰€æœ‰ã€‘å±¤ï¼Œè¨­å®š False åªæœƒæœå°‹ä¸‹ä¸€å±¤
                                  # string:    æœå°‹ tag åŒ…å«çš„æ–‡å­—
                                  # limit:     æœå°‹ tag å¾Œåªå›å‚³å¤šå°‘å€‹çµæœ

  soup.find_all()	                # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾å…¨éƒ¨å…§å®¹è£¡ã€æ‰€æœ‰ã€‘æŒ‡å®šçš„ tag
                                  # -> ResultSet[Tag]                                       
  soup.find()	                    # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾å…¨éƒ¨å…§å®¹è£¡ã€ç¬¬ä¸€å€‹ã€‘æ‰¾åˆ°çš„ tag
                                  # -> Tag

  soup.find_parents()             # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾çˆ¶å±¤ã€æ‰€æœ‰ã€‘æŒ‡å®šçš„ tag
                                  # -> ResultSet[Tag]
  soup.find_parent()	            # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾çˆ¶å±¤ã€ç¬¬ä¸€å€‹ã€‘æ‰¾åˆ°çš„ tag
                                  # -> Tag
  
  soup.find_next_siblings()       # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾åŒå±¤å¾Œæ–¹ã€æ‰€æœ‰ã€‘æŒ‡å®šçš„ tag
                                  # -> ResultSet[Tag]
  soup.find_next_sibling()        # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾åŒå±¤å¾Œæ–¹ã€ç¬¬ä¸€å€‹ã€‘æ‰¾åˆ°çš„ tag
                                  # -> Tag
                                      
  soup.find_previous_siblings()   # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾åŒå±¤å‰æ–¹ã€æ‰€æœ‰ã€‘æŒ‡å®šçš„ tag
                                  # -> ResultSet[Tag]
  soup.find_previous_sibling()    # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾åŒå±¤å‰æ–¹ã€ç¬¬ä¸€å€‹ã€‘æ‰¾åˆ°çš„ tag
                                  # -> Tag
                                      
  soup.find_all_next()            # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾å¾Œæ–¹å…§å®¹è£¡ã€æ‰€æœ‰ã€‘æŒ‡å®šçš„ tag
                                  # -> ResultSet[Tag]
  soup.find_next()                # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾å¾Œæ–¹å…§å®¹è£¡ã€ç¬¬ä¸€å€‹ã€‘æ‰¾åˆ°çš„ tag
                                  # -> Tag
                                      
  soup.find_all_previous()        # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾å‰æ–¹å…§å®¹è£¡ã€æ‰€æœ‰ã€‘æŒ‡å®šçš„ tag
                                  # -> ResultSet[Tag]
  soup.find_previous()            # ä»¥æ‰€åœ¨çš„ tag ä½ç½®ï¼Œå°‹æ‰¾å‰æ–¹å…§å®¹è£¡ã€ç¬¬ä¸€å€‹ã€‘æ‰¾åˆ°çš„ tag
                                  # -> Tag
  ```
### `ResultSet`
> ç¹¼æ‰¿è‡ª listï¼ŒTag çš„å®¹å™¨
+ å±¬æ€§
  ```py
  # source: éæ¿¾å™¨ï¼ŒSoupStrainer é¡åˆ¥
  ```

### `SoupStrainer`
> éæ¿¾å™¨

+ ...
  ```py
  # SoupStrainer è¢«ç”¨æ–¼æŒ‡å®šç¯©é¸æ¢ä»¶
  # åœ¨ BeautifulSoup ç‰©ä»¶å»ºç«‹ä¹‹å‰
  # é™åˆ¶åƒ…è§£æ <div class="contents_box02"></div> æ¨™ç±¤
  # é€™æ¨£å¯ä»¥ç¯€çœè§£æå¤§å‹æ–‡ä»¶æ™‚çš„æ™‚é–“å’Œè¨˜æ†¶é«”

  url = "https://www.taiwanlottery.com.tw/index_new.aspx"
  response = requests.get(url)
  strainer = SoupStrainer("div", {"class": "contents_box02"})
  soup = BeautifulSoup(response.text, "html.parser", parse_only=strainer)
  ```